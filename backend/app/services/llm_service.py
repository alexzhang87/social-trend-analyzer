import json
from abc import ABC, abstractmethod
from zhipuai import ZhipuAI
from typing import List, Dict, Any

# Import the central settings object
from ..core.config import settings
from ..data.models import database

class LLMProvider(ABC):
    """Abstract base class for a generic LLM provider."""
    @abstractmethod
    def generate_insights_for_cluster(self, cluster_posts: List[database.RawPost]) -> Dict[str, Any]:
        pass

class ZhipuAIProvider(LLMProvider):
    """LLM provider for ZhipuAI (GLM models)."""
    def __init__(self, api_key: str):
        if not api_key or api_key == "not_set":
            raise ValueError("ZhipuAI API key is required. Please check your .env file.")
        
        # Add a debug print to confirm the key is being loaded.
        print(f"DEBUG: Initializing ZhipuAI client with API Key: {api_key[:4]}...{api_key[-4:]}")
        
        self.client = ZhipuAI(api_key=api_key)
        self.model = "glm-4"

    def generate_insights_for_cluster(self, cluster_posts: List[database.RawPost]) -> Dict[str, Any]:
        print(f"Generating insights for a cluster of {len(cluster_posts)} posts with ZhipuAI ({self.model})...")
        
        # Ensure proper UTF-8 encoding for Chinese characters
        post_samples = []
        for post in cluster_posts[:20]:
            try:
                # Safely handle text encoding
                text = post.text[:250]
                if isinstance(text, bytes):
                    text = text.decode('utf-8', errors='ignore')
                post_samples.append(f"- {text}")
            except (UnicodeDecodeError, UnicodeEncodeError) as e:
                print(f"Warning: Skipping post due to encoding issue: {e}")
                continue
        
        combined_texts = "\n".join(post_samples)

        # This prompt is specifically tuned for GLM models
        prompt = f"""
你是一个专业的市场趋势分析师。请分析以下社交媒体帖子，并严格按照指定的JSON格式输出你的分析结果。不要在JSON对象之外添加任何解释性文字。

帖子样本:
---
{combined_texts}
---

请生成一个JSON对象，其结构如下:
{{
  "title": "为这个趋势起一个简洁、吸引人的标题 (字符串)",
  "summary": "用2-3句话总结这个趋势的核心讨论 (字符串)",
  "hot_score": "根据用户参与度和情感估算一个0-100的热度分数 (浮点数)",
  "category": "为这个趋势选择一个相关类别 (例如, '技术创新', '消费者抱怨') (字符串)",
  "insights": {{
    "pain_points": [{{ "text": "从用户讨论中识别出的一个具体痛点 (字符串)" }}],
    "opportunities": [{{ "text": "与痛点相关的潜在商业机会 (字符串)" }}],
    "mvp_plan": {{ "goal": "针对一个商业机会，用一句话描述一个为期一周的MVP目标 (字符串)" }}
  }},
  "emotion_analysis": {{
    "joy": "百分比 (0-100, 整数)",
    "neutral": "百分比 (0-100, 整数)",
    "anger": "百分比 (0-100, 整数)",
    "sadness": "百分比 (0-100, 整数)",
    "sarcasm": "百分比 (0-100, 整数)"
  }}
}}

请确保情感分析的百分比总和为100。请只提供原始的JSON对象作为你的回答。
"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},
            )
            
            # Safely get the content and parse it
            message_content = response.choices[0].message.content
            if not message_content:
                raise ValueError("LLM returned empty content, cannot parse JSON.")
            
            # When using json_object mode, the response content is already a valid JSON string.
            llm_json_output = json.loads(message_content)
            
            # Add top mentions (evidence), which are not generated by the LLM
            llm_json_output["top_mentions"] = [
                {
                    "platform": post.platform,
                    "author": post.author,
                    "text": post.text,
                    "url": post.url,
                    "likes": post.likes,
                    "sentiment": "Positive" # Placeholder
                } for post in cluster_posts[:3]
            ]
            
            print("ZhipuAI insight generation successful.")
            return llm_json_output

        except Exception as e:
            print(f"Error during ZhipuAI call or JSON parsing: {e}")
            return {
                "title": "Error: Failed to Generate Insights",
                "summary": str(e),
                "hot_score": 0,
                "category": "Error",
                "insights": {},
                "emotion_analysis": {},
                "top_mentions": []
            }

def get_llm_provider() -> LLMProvider:
    """
    Dependency injector to get the configured LLM provider.
    This is the 'adapter' that allows easy switching.
    """
    # Get the API key from our central settings object
    api_key = settings.ZHIPU_API_KEY
    if not api_key or api_key == "not_set":
        raise ValueError("ZHIPU_API_KEY environment variable not set or loaded correctly.")
    return ZhipuAIProvider(api_key=api_key)
